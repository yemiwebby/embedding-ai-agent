version: 2.1

executors:
  python-executor:
    docker:
      - image: cimg/python:3.10

jobs:
  deploy-and-analyze:
    executor: python-executor
    steps:
      - checkout

      - run:
          name: Verify Environment
          command: |
            echo "âœ… Environment check:"
            echo "- Python version: $(python3 --version)"
            echo "- Working directory: $(pwd)"
            echo "- OPENAI_API_KEY configured: ${OPENAI_API_KEY:+Yes}${OPENAI_API_KEY:-No}"
            echo "- OPENAI_API_KEY starts with: ${OPENAI_API_KEY:0:8}..."

      - run:
          name: Deploy Application (Simulate Deployment)
          command: |
            echo "ðŸš€ Simulating application deployment..."
            echo "ðŸ“¦ Installing application dependencies..."
            pip install -r app/requirements.txt
            echo "âœ… Application deployment completed"

      - run:
          name: Run Application Health Checks
          command: |
            echo "ðŸ” Running application health checks..."
            echo "âš ï¸  This will intentionally generate errors for demonstration"

            # Create logs directory if it doesn't exist
            mkdir -p logs

            # Make scripts executable
            chmod +x generate_errors.sh
            chmod +x scripts/run_analysis_pipeline.sh

            # Generate realistic errors by running the application
            echo "ðŸ“ Generating application logs with realistic errors..."
            ./generate_errors.sh || echo "Expected failures occurred during health checks"

      - run:
          name: AI-Powered Error Analysis
          command: |
            echo "ðŸ¤– Starting AI-powered error analysis..."
            echo "ðŸ“Š This is where the magic happens - AI analyzes the errors!"

            # Set up environment for AI analysis
            python3 -m venv analysis_env
            source analysis_env/bin/activate
            pip install --upgrade pip
            pip install embedchain openai requests beautifulsoup4 langdetect python-docx

            # Run the AI error analyzer (in scripts directory)
            python scripts/error_analyzer.py

      - run:
          name: Display Analysis Results
          command: |
            echo "ðŸ“‹ AI Analysis Results:"
            echo "======================"

            # Find the most recent analysis file
            ANALYSIS_FILE=$(ls -t error_analysis_*.md 2>/dev/null | head -1)

            if [ -n "$ANALYSIS_FILE" ]; then
              echo "ðŸ“„ Displaying AI analysis from: $ANALYSIS_FILE"
              echo ""
              cat "$ANALYSIS_FILE"
            else
              echo "âš ï¸  No analysis file found. Checking for logs..."
              if [ -f "logs/application.log" ]; then
                echo "ðŸ“ Raw application logs:"
                cat logs/application.log
              else
                echo "âŒ No logs or analysis found"
              fi
            fi

      - run:
          name: Archive Results
          command: |
            echo "ðŸ“ Archiving analysis results..."
            mkdir -p /tmp/analysis-results

            # Copy analysis files
            cp error_analysis_*.md /tmp/analysis-results/ 2>/dev/null || echo "No analysis files to archive"
            cp logs/application.log /tmp/analysis-results/ 2>/dev/null || echo "No log files to archive"

            echo "âœ… Results archived for review"

      - store_artifacts:
          path: /tmp/analysis-results
          destination: ai-analysis-results

workflows:
  deploy-and-analyze-errors:
    jobs:
      - deploy-and-analyze
